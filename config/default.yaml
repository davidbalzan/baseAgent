llm:
  provider: openrouter
  model: google/gemini-2.0-flash-001
  apiKey: ${OPENROUTER_API_KEY}
  costPerMInputTokens: 0.1
  costPerMOutputTokens: 0.4
  fallbackModels:
    - provider: openrouter
      model: z-ai/glm-5
  providers:
    anthropic:
      apiKey: ${ANTHROPIC_API_KEY}
    openai:
      apiKey: ${OPENAI_API_KEY}
    ollama:
      baseUrl: http://localhost:11434
channels:
  telegram:
    enabled: true
    token: ${TELEGRAM_BOT_TOKEN}
    allowedUserIds:
      - "1975268993"
      - "478902165"
  discord:
    enabled: true
    token: ${DISCORD_BOT_TOKEN}
agent:
  maxIterations: 35
  timeoutMs: 180000
  costCapUsd: 1
memory:
  compactionThreshold: 40000
  maxTokenBudget: 8000
  toolOutputDecayIterations: 6
  toolOutputDecayThresholdChars: 5000
  conversationHistoryTokenBudget: 40000
heartbeat:
  enabled: false
  intervalMs: 1800000
governance:
  read: auto-allow
  write: confirm
  exec: auto-allow
  toolOverrides:
    add_mcp_server: auto-allow  # user explicitly triggers this; confirmation is redundant
rateLimit:
  channel:
    maxRequests: 10
    windowMs: 60000
  http:
    maxRequests: 20
    windowMs: 60000
  tool:
    maxRequests: 50
    windowMs: 60000
server:
  port: 3000
  host: 0.0.0.0
mcp:
  servers:
    - name: chrome-devtools
      command: npx
      args:
        - -y
        - chrome-devtools-mcp@latest
        - --no-usage-statistics
      permission: read
      group: browser
    - name: context7
      command: npx
      args:
        - -y
        - "@upstash/context7-mcp@latest"
      permission: read
